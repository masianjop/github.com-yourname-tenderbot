from __future__ import annotations

import re
import logging
from dataclasses import dataclass
from datetime import datetime, date, timedelta
from typing import List, Optional, Dict

import requests
from bs4 import BeautifulSoup

log = logging.getLogger(__name__)

BASE_URL = "https://rostender.info/tender"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
}


@dataclass
class Tender:
    source: str           # "rostender"
    number: str           # 88109280
    published: date       # –¥–∞—Ç–∞ "–æ—Ç 22.11.25"
    title: str            # –ü–æ—Å—Ç–∞–≤–∫–∞ —á–µ–≥–æ-—Ç–æ —Ç–∞–º
    end_datetime: Optional[datetime]  # –û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö)
    city: Optional[str]
    region: Optional[str]
    price: Optional[int]          # –≤ —Ä—É–±–ª—è—Ö, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤
    price_raw: Optional[str]      # "6 375 000 ‚ÇΩ"
    url: Optional[str]            # —Å—Å—ã–ª–∫–∞-–ø–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É
    raw_block: str                # —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞, –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    detail_text: Optional[str] = None   # –î–ï–¢–ê–õ–¨–ù–û–ï –û–ü–ò–°–ê–ù–ò–ï –ò–ó –ö–ê–†–¢–û–ß–ö–ò


def _get_html(
    page: int = 1,
    session: Optional[requests.Session] = None,
) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞—Ç–∞–ª–æ–≥–∞ –†–æ—Å—Ç–µ–Ω–¥–µ—Ä–∞.
    page=1 ‚Äî –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, page=2 ‚Äî –≤—Ç–æ—Ä–∞—è –∏ —Ç.–¥.
    """
    sess = session or requests.Session()

    params = {}
    if page > 1:
        # /tender?page=2
        params["page"] = page

    log.info("–ó–∞–ø—Ä–∞—à–∏–≤–∞—é –∫–∞—Ç–∞–ª–æ–≥ –†–æ—Å—Ç–µ–Ω–¥–µ—Ä–∞: %s, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ %s", BASE_URL, page)
    resp = sess.get(BASE_URL, headers=HEADERS, params=params, timeout=30)
    resp.raise_for_status()
    return resp.text


def _iter_blocks(full_text: str):
    """
    –†–∞–∑–±–∏–≤–∞–µ–º —Å–ø–ª–æ—à–Ω–æ–π —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞ –±–ª–æ–∫–∏ –ø–æ '–¢–µ–Ω–¥–µ—Ä ‚Ññ... –æ—Ç ...'.
    """
    pattern = re.compile(
        r"–¢–µ–Ω–¥–µ—Ä\s+‚Ññ(?P<number>\d+)\s+–æ—Ç\s+(?P<date>\d{2}\.\d{2}\.\d{2})(?P<body>.*?)(?=–¢–µ–Ω–¥–µ—Ä\s+‚Ññ\d+\s+–æ—Ç|\Z)",
        re.S,
    )
    for m in pattern.finditer(full_text):
        yield m.group("number"), m.group("date"), m.group("body")


def _parse_price(lines: list[str]) -> tuple[Optional[int], Optional[str]]:
    for i, line in enumerate(lines):
        if line == "–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞" and i + 1 < len(lines):
            raw = lines[i + 1]
            # –ø—Ä–∏–º–µ—Ä: "6 375 000 ‚ÇΩ" –∏–ª–∏ "‚Äî"
            if "‚ÇΩ" in raw:
                digits = re.sub(r"[^\d]", "", raw)
                if digits:
                    return int(digits), raw
            return None, raw
    return None, None


def _parse_end_datetime(lines: list[str]) -> Optional[datetime]:
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É "–û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö)" –∏ –±–µ—Ä—ë–º –ª–∏–±–æ –¥–∞—Ç—É —Å –Ω–µ—ë,
    # –ª–∏–±–æ —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ –Ω–∞ —Å–∞–º–æ–π —Å—Ç—Ä–æ–∫–µ —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    for i, line in enumerate(lines):
        if line.startswith("–û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö)"):
            part = line.replace("–û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö)", "").strip()
            if not part and i + 1 < len(lines):
                # –¥–∞—Ç–∞/–≤—Ä–µ–º—è –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ
                part = lines[i + 1].strip()

            if not part:
                return None

            try:
                if " " in part:
                    return datetime.strptime(part, "%d.%m.%Y %H:%M")
                else:
                    d = datetime.strptime(part, "%d.%m.%Y").date()
                    return datetime(d.year, d.month, d.day)
            except ValueError:
                log.warning("–ù–µ —Å–º–æ–≥ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è: %r", part)
                return None
    return None


def _parse_city_region(lines: list[str]) -> tuple[Optional[str], Optional[str]]:
    """
    –í –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ —Å –û–∫–æ–Ω—á–∞–Ω–∏–µ–º:
    [ ... '–û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö)...', '–≥. –õ–æ–±–Ω—è', '–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å', ... ]
    """
    for i, line in enumerate(lines):
        if line.startswith("–û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö)") and i + 2 < len(lines):
            city = lines[i + 1]
            region = lines[i + 2]
            return city, region
    return None, None


def _cleanup_lines(body: str) -> list[str]:
    lines = [l.strip() for l in body.splitlines()]
    return [l for l in lines if l]  # —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ


def _fill_details(
    tenders: List[Tender],
    session: Optional[requests.Session] = None,
) -> None:
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–Ω–¥–µ—Ä–∞ –∑–∞—Ö–æ–¥–∏–º –ø–æ —Å—Å—ã–ª–∫–µ t.url –∏ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    sess = session or requests.Session()
    for t in tenders:
        if not t.url:
            continue
        try:
            log.info("–ó–∞–≥—Ä—É–∂–∞—é –¥–µ—Ç–∞–ª–∏ —Ç–µ–Ω–¥–µ—Ä–∞ %s: %s", t.number, t.url)
            resp = sess.get(t.url, headers=HEADERS, timeout=30)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.text, "html.parser")
            detail_text = soup.get_text("\n", strip=True)
            t.detail_text = detail_text
        except Exception as e:
            log.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —Ç–µ–Ω–¥–µ—Ä–∞ %s: %s", t.number, e)


def fetch_rostender_tenders(
    days: int = 1,
    max_pages: Optional[int] = None,
    with_details: bool = False,
    session: Optional[requests.Session] = None,
) -> List[Tender]:
    """
    –ó–∞–±–∏—Ä–∞–µ—Ç —Ç–µ–Ω–¥–µ—Ä—ã –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ –†–æ—Å—Ç–µ–Ω–¥–µ—Ä–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ `days` –¥–Ω–µ–π.

    –õ–æ–≥–∏–∫–∞:
      * –∏–¥—ë–º –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º 1..N (–ø–æ–∫–∞ –µ—Å—Ç—å —Ç–µ–Ω–¥–µ—Ä—ã –Ω–æ–≤–µ–µ –ø–æ—Ä–æ–≥–∞)
      * –ø–∞—Ä—Å–∏–º –±–ª–æ–∫–∏ "–¢–µ–Ω–¥–µ—Ä ‚Ññ... –æ—Ç ..."
      * –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–µ–Ω–¥–µ—Ä—ã —Å—Ç–∞—Ä—à–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
      * –∑–∞—â–∏—â–∞–µ–º—Å—è –æ—Ç –¥—É–±–ª–µ–π –ø–æ –Ω–æ–º–µ—Ä—É.

    –ï—Å–ª–∏ max_pages=None ‚Äî –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –¥–∞—Ç–æ–π.
    –ï—Å–ª–∏ with_details=True ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ö–æ–¥–∏–º –≤ –∫–∞–∂–¥—ã–π —Ç–µ–Ω–¥–µ—Ä –ø–æ t.url –∏ —Ç—è–Ω–µ–º detail_text.
    """

    today = date.today()
    min_date = today - timedelta(days=days)

    sess = session or requests.Session()
    tenders_by_number: Dict[str, Tender] = {}

    page = 1
    while True:
        if max_pages is not None and page > max_pages:
            log.info(
                "–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ø—Ä–µ–¥–µ–ª max_pages=%s, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è. –°–µ–π—á–∞—Å —Ç–µ–Ω–¥–µ—Ä–æ–≤: %d",
                max_pages,
                len(tenders_by_number),
            )
            break

        html = _get_html(page=page, session=sess)
        soup = BeautifulSoup(html, "html.parser")
        text = soup.get_text("\n", strip=True)

        page_added_any = False
        added_this_page = 0

        for number, date_str, body in _iter_blocks(text):
            # 1) –¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            try:
                # –Ω–∞ —Å–∞–π—Ç–µ –≥–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "25" -> —Å—á–∏—Ç–∞–µ–º 20xx
                d = datetime.strptime(date_str, "%d.%m.%y").date()
            except ValueError:
                log.warning(
                    "–ù–µ —Å–º–æ–≥ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ %r —É —Ç–µ–Ω–¥–µ—Ä–∞ %s",
                    date_str,
                    number,
                )
                continue

            if d < min_date:
                # —Å—Ç–∞—Ä—ã–π —Ç–µ–Ω–¥–µ—Ä, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue

            if number in tenders_by_number:
                # —É–∂–µ –¥–æ–±–∞–≤–ª—è–ª–∏ —ç—Ç–æ—Ç —Ç–µ–Ω–¥–µ—Ä —Å –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                continue

            lines = _cleanup_lines(body)
            if not lines:
                log.debug("–ü—É—Å—Ç–æ–π –±–ª–æ–∫ —É —Ç–µ–Ω–¥–µ—Ä–∞ %s", number)
                continue

            # 2) –Ω–∞–∑–≤–∞–Ω–∏–µ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ "–¢–µ–Ω–¥–µ—Ä ‚Ññ... –æ—Ç ...")
            title = lines[0]

            # 3) –æ–∫–æ–Ω—á–∞–Ω–∏–µ, –≥–æ—Ä–æ–¥, —Ä–µ–≥–∏–æ–Ω, —Ü–µ–Ω–∞
            end_dt = _parse_end_datetime(lines)
            city, region = _parse_city_region(lines)
            price, price_raw = _parse_price(lines)

            # 4) —Å—Å—ã–ª–∫–∞ (–ø–æ–∏—Å–∫ –ø–æ –Ω–æ–º–µ—Ä—É)
            url = f"https://rostender.info/tender?search={number}"

            tender = Tender(
                source="rostender",
                number=number,
                published=d,
                title=title,
                end_datetime=end_dt,
                city=city,
                region=region,
                price=price,
                price_raw=price_raw,
                url=url,
                raw_block=body.strip(),
            )
            tenders_by_number[number] = tender
            page_added_any = True
            added_this_page += 1

        log.info(
            "–°—Ç—Ä–∞–Ω–∏—Ü–∞ %s: –¥–æ–±–∞–≤–ª–µ–Ω–æ %d —Ç–µ–Ω–¥–µ—Ä–∞(–æ–≤), –≤—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–Ω–¥–µ—Ä–æ–≤: %d",
            page,
            added_this_page,
            len(tenders_by_number),
        )

        # –ï—Å–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤–æ–æ–±—â–µ –Ω–µ –ø–æ—è–≤–∏–ª–æ—Å—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –Ω–æ–≤–æ–≥–æ —Ç–µ–Ω–¥–µ—Ä–∞
        # –∑–∞ –Ω–∞—à –ø–µ—Ä–∏–æ–¥, —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–∞–ª—å—à–µ —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ä—ã–µ –∏ –≤—ã—Ö–æ–¥–∏–º.
        if not page_added_any:
            log.info(
                "–ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ %s –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –Ω–æ–≤–µ–µ %s, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Å—å.",
                page,
                min_date.strftime("%d.%m.%Y"),
            )
            break

        page += 1

    results = list(tenders_by_number.values())

    if with_details and results:
        log.info("–ó–∞–≥—Ä—É–∂–∞—é –¥–µ—Ç–∞–ª–∏ –¥–ª—è %d —Ç–µ–Ω–¥–µ—Ä–æ–≤...", len(results))
        _fill_details(results, session=sess)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏ –Ω–æ–º–µ—Ä—É (—Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –Ω–∞–≤–µ—Ä—Ö—É)
    results.sort(key=lambda t: (t.published, t.number), reverse=True)
    log.info(
        "–ò—Ç–æ–≥–æ: –Ω–∞—à—ë–ª %d —Ç–µ–Ω–¥–µ—Ä–æ–≤ –†–æ—Å—Ç–µ–Ω–¥–µ—Ä–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ %d –¥–Ω.",
        len(results),
        days,
    )
    return results


def format_tender_for_telegram(t: Tender) -> str:
    price_part = f"{t.price_raw}" if t.price_raw else "‚Äî"
    end_part = t.end_datetime.strftime("%d.%m.%Y %H:%M") if t.end_datetime else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    place = " / ".join(p for p in [t.city, t.region] if p)

    return (
        f"üìå {t.title}\n"
        f"‚Ññ {t.number} –æ—Ç {t.published.strftime('%d.%m.%Y')}\n"
        f"üìç {place or '–º–µ—Å—Ç–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'}\n"
        f"‚è± –û–∫–æ–Ω—á–∞–Ω–∏–µ (–ú–°–ö): {end_part}\n"
        f"üí∞ –ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: {price_part}\n"
        f"üîó {t.url}"
    )

